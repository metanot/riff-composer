from model import create_network

import pandas as pd
import json
import numpy
from music21 import instrument, note, stream, chord
from keras.utils import np_utils


def generate():
    """ Generate a piano midi file """
    # load the notes used to train the model
    with open('data/notes.json', 'r') as filename:
        notes = json.load(filename)

    with open("data/pitch_vocab.json", "r") as filename:
        pitch_vocab = json.load(filename)

    with open("data/duration_vocab.json", "r") as filename:
        duration_vocab = json.load(filename)

    look_back = 4

    model = create_network(timesteps=look_back,
                           pitch_vocab_size=len(pitch_vocab),
                           duration_vocab_size=len(duration_vocab))

    model.load_weights('weights/weights.hdf5')

    model.summary()

    notes_df = pd.DataFrame(notes, columns=['pitch', 'duration'])
    pitch_samples, duration_samples = prepare_samples(notes_df, pitch_vocab, duration_vocab, look_back)

    print("\npitch_samples:")
    print(pitch_samples)

    print("\nduration_samples:")
    print(duration_samples)

    pitches, durations = generate_notes(model, pitch_samples, duration_samples, pitch_vocab, duration_vocab, count=16)

    # with open("predicted_pitches.json", "w") as filename:
    #     json.dump(pitches, filename)
    #
    # with open("predicted_durations.json", "w") as filename:
    #     json.dump(durations, filename)

    # create_midi(pitches, durations)


def prepare_samples(notes, pitch_vocab, duration_vocab, look_back):
    pitches = notes['pitch']
    durations = notes['duration']

    pitch_to_int = dict((pitch, number) for number, pitch in enumerate(pitch_vocab))
    duration_to_int = dict((duration, number) for number, duration in enumerate(duration_vocab))

    pitch_samples = []
    duration_samples = []

    for i in range(notes.shape[0] - look_back):
        pitch_sequence_in = pitches[i:(i + look_back)]
        duration_sequence_in = durations[i:(i + look_back)]
        pitch_samples.append([pitch_to_int[char] for char in pitch_sequence_in])
        duration_samples.append([duration_to_int[char] for char in duration_sequence_in])

    pitch_samples = numpy.array(pitch_samples)
    duration_samples = numpy.array(duration_samples)

    pitch_samples = np_utils.to_categorical(pitch_samples)
    duration_samples = np_utils.to_categorical(duration_samples)

    return pitch_samples, duration_samples


def generate_notes(model, pitch_samples, duration_samples, pitch_vocab, duration_vocab, count):
    """ Generate notes from the neural network based on a sequence of notes """
    # pick a random sequence from the input as a starting point for the prediction
    start = numpy.random.randint(0, len(pitch_samples) - 1)

    int_to_pitch = dict((number, pitch) for number, pitch in enumerate(pitch_vocab))
    int_to_duration = dict((number, duration) for number, duration in enumerate(duration_vocab))

    pitch_sample = pitch_samples[start]
    duration_sample = duration_samples[start]

    pitch_sample = numpy.array(pitch_sample)
    duration_sample = numpy.array(duration_sample)

    pitch_sample = numpy.reshape(pitch_sample, (1, pitch_sample.shape[0], len(pitch_vocab)))
    duration_sample = numpy.reshape(duration_sample, (1, duration_sample.shape[0], len(duration_vocab)))

    # print("\npitch_sample:")
    # print(pitch_sample)
    #
    # print("\nduration_sample:")
    # print(duration_sample)

    pitches = []
    durations = []

    for note_index in range(count):
        predicted_pitch, predicted_duration = model.predict([pitch_sample, duration_sample], verbose=0)

        pitch_index = numpy.argmax(predicted_pitch)
        duration_index = numpy.argmax(predicted_duration)

        pitch_name = int_to_pitch[pitch_index]
        duration_name = int_to_duration[duration_index]

        pitches.append(pitch_name)
        durations.append(duration_name)

        predicted_pitch = np_utils.to_categorical(pitch_index, num_classes=len(pitch_vocab))
        predicted_duration = np_utils.to_categorical(duration_index, num_classes=len(duration_vocab))

        predicted_pitch = numpy.reshape(predicted_pitch, (1, 1, len(pitch_vocab)))
        predicted_duration = numpy.reshape(predicted_duration, (1, 1, len(duration_vocab)))

        pitch_sample = numpy.append(pitch_sample, predicted_pitch)
        # pitch_sample = pitch_sample[1:len(pitch_sample)]

        print("")

        duration_sample = numpy.append(duration_sample, predicted_duration)
        # duration_sample = duration_sample[1:len(duration_sample)]

        print("")

    return pitches, durations


# def create_midi(pitches, durations):
#     offset = 0
#     output_notes = []
#
#     # create note and chord objects based on the values generated by the model
#     for pitch, duration in pitches, durations:
#         # pattern is a chord
#         if ('.' in pitch):
#             notes_in_chord = pitch.split('.')
#             notes = []
#             for name in notes_in_chord:
#                 new_note = note.Note(name)
#                 new_note.storedInstrument = instrument.Piano()
#                 notes.append(new_note)
#             new_chord = chord.Chord(notes)
#             new_chord.offset = offset
#             new_chord.duration.quarterLength = 0.25
#             print(new_chord.tie)
#             output_notes.append(new_chord)
#         # pattern is a rest
#         elif ('rest' in pattern):
#             new_rest = note.Rest()
#             new_rest.offset = offset
#             new_rest.duration.quarterLength = 0.25
#             new_rest.storedInstrument = instrument.Piano()
#             print(new_rest.tie)
#             output_notes.append(new_rest)
#         # pattern is a note
#         else:
#             new_note = note.Note(pattern)
#             new_note.offset = offset
#             new_note.duration.quarterLength = 0.25
#             note.storedInstrument = instrument.Piano()
#             print(new_note.tie)
#             output_notes.append(new_note)
#
#         # increase offset each iteration so that notes do not stack
#         offset += 0.25
#
#     midi_stream = stream.Stream(output_notes)
#
#     midi_stream.write('midi', fp='output.mid')


if __name__ == '__main__':
    generate()
